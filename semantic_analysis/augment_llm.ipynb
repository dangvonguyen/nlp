{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from google.generativeai.types import HarmBlockThreshold, HarmCategory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.5-flash'\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=model_name,\n",
    "    temperature=0.95,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    model_kwargs={\n",
    "        'frequency_penalty': 0.5,\n",
    "        'presence_penalty': 0.4,\n",
    "    },\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['free_text', 'label_id'],\n",
       "        num_rows: 24048\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['free_text', 'label_id'],\n",
       "        num_rows: 2672\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['free_text', 'label_id'],\n",
       "        num_rows: 6680\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('sonlam1102/vihsd')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean samples: 19886\n",
      "Number of offensive samples: 1606\n",
      "Number of hate samples: 2556\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame(dataset['train'])\n",
    "\n",
    "clean_data = train[train['label_id'] == 0]\n",
    "offensive_data = train[train['label_id'] == 1]\n",
    "hate_data = train[train['label_id'] == 2]\n",
    "\n",
    "print(f\"Number of clean samples: {len(clean_data)}\")\n",
    "print(f\"Number of offensive samples: {len(offensive_data)}\")\n",
    "print(f\"Number of hate samples: {len(hate_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df_mapping = {\n",
    "    0: clean_data,\n",
    "    1: offensive_data,\n",
    "    2: hate_data,\n",
    "}\n",
    "\n",
    "label_mapping = {\n",
    "    0: \"CLEAN\",\n",
    "    1: \"OFFENSIVE\", \n",
    "    2: \"HATE\"\n",
    "}\n",
    "\n",
    "label_descriptions = {\n",
    "    0: \"clean, non-offensive social media text without harmful content\",\n",
    "    1: \"offensive social media text with inappropriate language, profanity, or rude behavior but not targeted hate\",\n",
    "    2: \"hate media speech targeting specific groups, individuals, or demographics with harmful, discriminatory intent\"\n",
    "}\n",
    "\n",
    "label_guidance = {\n",
    "    0: (\n",
    "        'Friendly conversations, compliments, questions, daily life topics',\n",
    "        'Supportive comments, light humor, neutral observations',\n",
    "        'Casual chats between friends, family interactions',\n",
    "        'Entertainment discussions, hobby talks, positive reactions',\n",
    "    ),\n",
    "    1: (\n",
    "        'Rude language, complaints, arguments, crude humor',\n",
    "        'Mild insults, inappropriate jokes, vulgar expressions',\n",
    "        'Frustrated reactions, sarcastic comments, disrespectful tone',\n",
    "        'Personal attacks that are rude but not targeting protected groups',\n",
    "    ),\n",
    "    2: (\n",
    "        'Discriminatory language targeting specific groups or individuals',\n",
    "        'Hostile comments with intent to harm or demean',\n",
    "        'Prejudiced statements based on identity, appearance, or characteristics',\n",
    "        'Aggressive targeting with malicious intent',\n",
    "    ),\n",
    "}\n",
    "\n",
    "system_prompt = 'You are an expert at generating authentic Vietnamese social media content that matches real-world online conversations. You understand Vietnamese internet culture, slang, teen code, and social media patterns. Generate content that reflects genuine Vietnamese online behavior and language use.'\n",
    "\n",
    "prompt = \"\"\"You are generating authentic Vietnamese social media text for data augmentation. Carefully study the patterns, language style, and intensity levels from the examples below.\n",
    "\n",
    "**LABEL:** {label_name} - {label_desc}\n",
    "\n",
    "**TRAINING EXAMPLES** ({n_examples} total):\n",
    "{examples_text}\n",
    "\n",
    "**TASK:** Generate {n_generate} new Vietnamese sentences with the SAME LABEL ({label_name}).\n",
    "\n",
    "## VIETNAMESE SOCIAL MEDIA AUTHENTICITY:\n",
    "\n",
    "### 1. Vietnamese Internet Language Patterns\n",
    "- **Common teen code:** k/ko (kh√¥ng), dc/ƒëc (ƒë∆∞·ª£c), vs (v·ªõi), trc (tr∆∞·ªõc), cx (c≈©ng), mik (m√¨nh), j (g√¨), r (r·ªìi), m/t (tao/m√†y), etc.\n",
    "- **Abbreviations:** fb (Facebook), zl (Zalo), haha/hehe, oke/ok, tks/ty (thanks), etc.\n",
    "\n",
    "### 2. Emotional Expression\n",
    "- **Emojis:** üòÇ, üò≠, üëç, ‚ù§Ô∏è, ü§Æ, üò°, etc.\n",
    "- **Emoticons:** :)), =)), :((, </3, <3, :v, etc.\n",
    "\n",
    "### 3. Intensity Matching (CRITICAL)\n",
    "- Carefully analyze the **emotional intensity level** of examples\n",
    "- Match the **tone and aggression**\n",
    "- Preserve the authentic **Vietnamese expression style**\n",
    "\n",
    "### 4. Content Focus\n",
    "**Target themes:** {content_guidance}\n",
    "\n",
    "**OUTPUT FORMAT:**\n",
    "Each sentence on a new line, numbered (1., 2., 3., ...)\n",
    "\n",
    "**CRITICAL REQUIREMENTS:**\n",
    "- Include emojis/emoticons or internet slang/abbreviations more often\n",
    "- Include random names of people or groups more often\n",
    "- Generate sentences with realistic Vietnamese social media length diversity\n",
    "- DO NOT copy directly from examples\n",
    "- Maintain exact label-appropriate intensity level\n",
    "- Use authentic Vietnamese internet language\n",
    "\n",
    "**GENERATE {n_generate} VIETNAMESE SENTENCES:**\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(label: int, n_examples: int = 5, n_generate: int = 10) -> str:\n",
    "    label_name = label_mapping[label]\n",
    "    label_desc = label_descriptions[label]\n",
    "    content_guidance = '\\n- '.join([''] + list(label_guidance[label]))\n",
    "\n",
    "    label_df = label_df_mapping[label]\n",
    "    examples = label_df.sample(n=n_examples)['free_text'].tolist()\n",
    "    examples_text = '\\n'.join(f'{i + 1}. {ex}' for i, ex in enumerate(examples))\n",
    "\n",
    "    return prompt.format(\n",
    "        label_name=label_name,\n",
    "        label_desc=label_desc,\n",
    "        examples_text=examples_text,\n",
    "        n_examples=n_examples,\n",
    "        n_generate=n_generate,\n",
    "        content_guidance=content_guidance,\n",
    "    )\n",
    "\n",
    "def generate_augmented_text(prompt: str, max_retries: int = 3) -> list[str]:\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            messages = [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ]\n",
    "            response = model.invoke(messages)\n",
    "\n",
    "            generated_text = response.content.strip()\n",
    "            sentences = [\n",
    "                s.strip().split(' ', maxsplit=1)[1].strip()\n",
    "                for s in generated_text.split('\\n')\n",
    "                if s.strip()\n",
    "            ]\n",
    "            return sentences\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print(f\"Failed to generate text after {max_retries} attempts.\")\n",
    "                return []\n",
    "\n",
    "def augment_dataset(\n",
    "    label: int,\n",
    "    total_samples: int = 1000,\n",
    "    n_examples: int = 5,\n",
    "    n_generate: int = 10,\n",
    "    output_dir: str = 'data',\n",
    ") -> pd.DataFrame:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_name = f'aug_llm_{label_mapping[label].lower()}.csv'\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    augmented_data = pd.DataFrame(columns=['free_text', 'label_id'])\n",
    "    for i in range(total_samples // n_generate):\n",
    "        prompt = create_prompt(label, n_examples, n_generate)\n",
    "        augmented_text = generate_augmented_text(prompt)\n",
    "        augmented_text = pd.DataFrame({'free_text': augmented_text, 'label_id': label})\n",
    "        augmented_data = pd.concat([augmented_data, augmented_text], ignore_index=True)\n",
    "\n",
    "        # Append new data to file\n",
    "        write_header = not os.path.exists(file_path)\n",
    "        augmented_text.to_csv(\n",
    "            file_path, sep='|', mode='a', index=False, header=write_header\n",
    "        )\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M·∫•y th·∫±ng l·ªìn n√†y r·∫£nh qu√° h·∫£? üòÇ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clm t∆∞·ªüng hay l·∫Øm √†? Ngu v√£i √≤.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒêm c√°i m·ªìm n√≥i chuy·ªán nh∆∞ c√°i chu·ªìng g√†.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nh√¨n m·∫∑t ƒë√£ th·∫•y gh√©t r·ªìi, s·ªßa c√°i g√¨ n·ªØa?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Th√¥i d·∫πp m·∫π ƒëi, n√≥i nhi·ªÅu nh·ª©c ƒë·∫ßu.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>ƒÇn b√°m nh∆∞ ch√≥.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>ƒêm b·∫©n th·ªâu.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Th·∫±ng th·∫•t b·∫°i.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>M√†y c√¢m m·∫π m√†y ƒëi.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>ƒê√©o ai th√®m quan t√¢m ƒë√¢u.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       free_text  label_id\n",
       "0               M·∫•y th·∫±ng l·ªìn n√†y r·∫£nh qu√° h·∫£? üòÇ         1\n",
       "1                Clm t∆∞·ªüng hay l·∫Øm √†? Ngu v√£i √≤.         1\n",
       "2       ƒêm c√°i m·ªìm n√≥i chuy·ªán nh∆∞ c√°i chu·ªìng g√†.         1\n",
       "3     Nh√¨n m·∫∑t ƒë√£ th·∫•y gh√©t r·ªìi, s·ªßa c√°i g√¨ n·ªØa?         1\n",
       "4            Th√¥i d·∫πp m·∫π ƒëi, n√≥i nhi·ªÅu nh·ª©c ƒë·∫ßu.         1\n",
       "...                                          ...       ...\n",
       "4995                             ƒÇn b√°m nh∆∞ ch√≥.         1\n",
       "4996                                ƒêm b·∫©n th·ªâu.         1\n",
       "4997                             Th·∫±ng th·∫•t b·∫°i.         1\n",
       "4998                          M√†y c√¢m m·∫π m√†y ƒëi.         1\n",
       "4999                   ƒê√©o ai th√®m quan t√¢m ƒë√¢u.         1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_dataset(label=1, total_samples=5000, n_examples=50, n_generate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Con nh·ªè ƒë√≥ nh√¨n gh√©t vcl, ƒë√∫ng l√† lo·∫°i n√£o t√†n!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M·∫•y th·∫±ng ƒÉn h·∫°i n√†y ch·ªâ gi·ªèi ph√° ho·∫°i ƒë·∫•t n∆∞·ªõ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Th·∫±ng Ad m√†y l√†m ƒÉn nh∆∞ clgv?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ƒêm l≈© ba que x·ªè l√°, c√∫t v·ªÅ x·ª© t·ª•i m√†y ƒëi.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M·∫∑t con *** ƒë√≥ nh√¨n ƒë√£ th·∫•y mu·ªën ƒë·∫•m r·ªìi.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>ƒêm c√°i l≈© ph·∫£n ƒë·ªông, b√°n n∆∞·ªõc h·∫°i d√¢n.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>B·ªçn nh√† gi√†u m·ªõi n·ªïi to√†n ƒë·ªì khoe c·ªßa, n√£o t√†n.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Con b√© n√†y ƒë√∫ng l√† ƒë·ªì ph·∫ø v·∫≠t, ko l√†m ƒë∆∞·ª£c t√≠c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>M·∫•y th·∫±ng ƒÉn xin nh√¨n gh√™ v√£i, to√†n ƒë·ªì l·ª´a ƒë·∫£o.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>ƒêm c√°i b·ªçn chuy√™n ƒëi l·ª´a ƒë·∫£o ng∆∞·ªùi gi√†, ƒë√∫ng l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              free_text label_id\n",
       "0       Con nh·ªè ƒë√≥ nh√¨n gh√©t vcl, ƒë√∫ng l√† lo·∫°i n√£o t√†n!        2\n",
       "1     M·∫•y th·∫±ng ƒÉn h·∫°i n√†y ch·ªâ gi·ªèi ph√° ho·∫°i ƒë·∫•t n∆∞·ªõ...        2\n",
       "2                         Th·∫±ng Ad m√†y l√†m ƒÉn nh∆∞ clgv?        2\n",
       "3             ƒêm l≈© ba que x·ªè l√°, c√∫t v·ªÅ x·ª© t·ª•i m√†y ƒëi.        2\n",
       "4             M·∫∑t con *** ƒë√≥ nh√¨n ƒë√£ th·∫•y mu·ªën ƒë·∫•m r·ªìi.        2\n",
       "...                                                 ...      ...\n",
       "4995             ƒêm c√°i l≈© ph·∫£n ƒë·ªông, b√°n n∆∞·ªõc h·∫°i d√¢n.        2\n",
       "4996    B·ªçn nh√† gi√†u m·ªõi n·ªïi to√†n ƒë·ªì khoe c·ªßa, n√£o t√†n.        2\n",
       "4997  Con b√© n√†y ƒë√∫ng l√† ƒë·ªì ph·∫ø v·∫≠t, ko l√†m ƒë∆∞·ª£c t√≠c...        2\n",
       "4998    M·∫•y th·∫±ng ƒÉn xin nh√¨n gh√™ v√£i, to√†n ƒë·ªì l·ª´a ƒë·∫£o.        2\n",
       "4999  ƒêm c√°i b·ªçn chuy√™n ƒëi l·ª´a ƒë·∫£o ng∆∞·ªùi gi√†, ƒë√∫ng l...        2\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment_dataset(label=2, total_samples=5000, n_examples=50, n_generate=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
